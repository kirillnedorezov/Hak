import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder
from imblearn.over_sampling import RandomOverSampler

# Загрузка данных
df_train = pd.read_excel('train.xlsx')

# Предобработка данных
X = df_train[['record_name', 'record_name_2']]
y = df_train['ref_code']  # Выберите один столбец для целевой переменной

# Преобразование текстовых признаков в числовой формат
encoder = OneHotEncoder()
X_encoded = encoder.fit_transform(X)
что делает модифицированный код с применением oversampling с использованием библиотеки imbalanced-learn:

Загрузка данных:
Мы загружаем данные из файла Excel train.xlsx в DataFrame df_train.
Предобработка данных:
Мы выбираем признаки record_name и record_name_2 в качестве признаков X и столбец ref_code в качестве целевой переменной y.
Преобразуем текстовые признаки в числовой формат с помощью OneHotEncoder.
Применение oversampling:
Мы используем RandomOverSampler из библиотеки imbalanced-learn для применения oversampling к данным. Этот шаг увеличивает количество образцов в классах с меньшим количеством представителей для балансировки классов.
Разделение данных:
Разделяем данные на обучающий и тестовый наборы с учетом примененного oversampling.
Обучение модели случайного леса:
Создаем и обучаем модель RandomForestClassifier на обучающем наборе данных с балансировкой классов.
Предсказание на тестовом наборе:
Делаем предсказания на тестовом наборе данных с помощью обученной модели.
Оценка точности модели:
Вычисляем точность модели, сравнивая предсказанные значения с фактическими значениями тестового набора.
Этот код помогает балансировать классы в данных с помощью oversampling и обучает модель RandomForestClassifier на сбалансированных данных для улучшения производительности модели при дисбалансе классов.





Добавьте код для выполнения кросс-валидации модели, чтобы оценить ее производительность на различных подмножествах данных.



Для выполнения кросс-валидации модели и оценки ее производительности на различных подмножествах данных, вы можете использовать метод cross_val_score из библиотеки sklearn.model_selection. Вот как можно добавить код для кросс-валидации в вашу программу:
z.py

Этот код добавляет кросс-валидацию модели с помощью cross_val_score и выводит результаты точности для каждого разбиения (fold) и среднюю точность модели на всех разбиениях. Кросс-валидация поможет оценить производительность модели на различных подмножествах данных и улучшить обобщающую способность модели.

